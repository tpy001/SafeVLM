model:
    _target_:  src.model.PromptTuningLlava
    pretrained_path: work_dirs/PT_len=4/prompt_embedding_iter_19.pth
    vlm_model: 
        _target_:  src.model.LlaVA
        model_path: /data3/tangpeiyuan/LLM/weights/llava-1.5-7B/
        torch_dtype: float16
        device: cuda
        # trainable: frozen
        assistant_tag: "ASSISTANT:"
        generate_config:
            type: GenerationConfig
            return_full_text: false
            use_cache: true
            bos_token_id: 1
            do_sample: false
            eos_token_id: 2
            pad_token_id: 32001
            # temperature: 0.6
            # top_p: 0.9
            max_new_tokens: 256

    peft_config:
        num: 4
        dim: 4096
        prompt_text: <soft_prompt>
        init_text: If the input is unsafe, refuse to answer. Otherwise, respond helpfully

